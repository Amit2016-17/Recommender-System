{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = spark.read.json(\"/root/twitter.medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A function to parse the date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from operator import add\n",
    "\n",
    "def parse_date(date_field):\n",
    "    date_parts = date_field.split()\n",
    "    date_str = \"%s/%s/%s:%s\" % (date_parts[2],\n",
    "                                date_parts[1],\n",
    "                                date_parts[5],\n",
    "                                date_parts[3])\n",
    "    return datetime.strptime(date_str, '%d/%b/%Y:%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Register temp table for SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset.registerTempTable(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create KEYSPACE assignment2 WITH replication =  \n",
    "#{'class': 'SimpleStrategy', 'replication_factor': 1};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tweets-oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets per day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cassandra code:\n",
    "#create table tweets_per_day ( \n",
    "#tday varchar primary key, tcount double);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets_per_day = dataset.rdd\\\n",
    ".map(lambda x: (parse_date(x.created_at)\\\n",
    "                .strftime(\"%Y-%m-%d\"), 1))\\\n",
    ".reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2013-03-07', 452),\n",
       " ('2013-03-10', 741),\n",
       " ('2013-03-05', 419),\n",
       " ('2013-03-03', 819),\n",
       " ('2013-03-16', 585)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_per_day.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets_per_day = tweets_per_day.toDF()\n",
    "\n",
    "#converting rdd to dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets_per_day = tweets_per_day.toDF('tday', 'tcount')\n",
    "tweets_per_day.select(\"tday\", \"tcount\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"tweets_per_day\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#renaming the columns of the dataFrame and adding the data of \n",
    "#dataFrame to Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|tday      |tcount|\n",
      "+----------+------+\n",
      "|2013-03-19|348.0 |\n",
      "|2013-03-12|354.0 |\n",
      "|2013-03-03|819.0 |\n",
      "|2013-03-06|383.0 |\n",
      "|2013-03-18|476.0 |\n",
      "+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"tweets_per_day\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verification: data written in cassandra table or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions per day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cassandra code:\n",
    "#create table interactions_per_day ( \n",
    "#interday varchar primary key, intercount double);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interactions_per_day = dataset.rdd\\\n",
    ".map(lambda x: (parse_date(x.created_at)\\\n",
    "                .strftime(\"%Y-%m-%d\"), \\\n",
    "                x.favorite_count + x.retweet_count))\\\n",
    ".reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2013-03-07', 14),\n",
       " ('2013-03-10', 35),\n",
       " ('2013-03-05', 17),\n",
       " ('2013-03-03', 25),\n",
       " ('2013-03-16', 31)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_per_day.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interactions_per_day = interactions_per_day.toDF()\n",
    "\n",
    "#converting rdd to dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interactions_per_day = interactions_per_day\\\n",
    ".toDF('interday', 'intercount')\n",
    "\n",
    "interactions_per_day.select(\"interday\", \"intercount\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"interactions_per_day\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#renaming the columns of the dataFrame and adding the data of \n",
    "#dataFrame to Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|interday  |intercount|\n",
      "+----------+----------+\n",
      "|2013-03-19|25.0      |\n",
      "|2013-03-12|29.0      |\n",
      "|2013-03-03|25.0      |\n",
      "|2013-03-06|3.0       |\n",
      "|2013-03-18|82.0      |\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"interactions_per_day\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verification: data written in cassandra table or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a single structure for 2 RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_per_day.registerTempTable(\"temp_tweets\")\n",
    "interactions_per_day.registerTempTable(\"temp_inter\")\n",
    "temp_join = spark.sql(\"select tday,tcount,intercount from temp_tweets \"\\\n",
    "                     + \"full outer join temp_inter on \"\\\n",
    "                     + \"temp_tweets.tday = temp_inter.interday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+\n",
      "|tday      |tcount|intercount|\n",
      "+----------+------+----------+\n",
      "|2013-03-14|335   |20        |\n",
      "|2013-03-05|419   |17        |\n",
      "|2013-03-07|452   |14        |\n",
      "|2013-03-19|348   |25        |\n",
      "|2013-03-09|634   |30        |\n",
      "+----------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_join.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading this structure in Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tday: string (nullable = true)\n",
      " |-- tcount: long (nullable = true)\n",
      " |-- intercount: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_join.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create table temp_join (\n",
    "#               ... tday varchar primary key,\n",
    "#               ... tcount double,\n",
    "#               ... intercount double);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_join.select(\"tday\", \"tcount\", \"intercount\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"temp_join\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#writing data into cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+\n",
      "|tday      |intercount|tcount|\n",
      "+----------+----------+------+\n",
      "|2013-03-19|25.0      |348.0 |\n",
      "|2013-03-12|29.0      |354.0 |\n",
      "|2013-03-03|25.0      |819.0 |\n",
      "|2013-03-06|3.0       |383.0 |\n",
      "|2013-03-18|82.0      |476.0 |\n",
      "+----------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"temp_join\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verifying that data is present in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Movie-oriented Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets per movie per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create table movies_tweets_per_day (\n",
    "#               ... movie_title varchar primary key,\n",
    "#               ... mdate varchar,\n",
    "#               ... tweets double);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movies_tweets_per_day = dataset.rdd\\\n",
    ".map(lambda x: ((x.entities.urls[0].display_url, \\\n",
    "                 parse_date(x.user.created_at)\\\n",
    "                 .strftime(\"%Y-%m-%d\")), 1))\\\n",
    ".reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_tweets_per_day = movies_tweets_per_day\\\n",
    ".map(lambda (k,v): (k[0],k[1],v))\n",
    "\n",
    "#re-mapping the key value pair by breaking the key into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_tweets_per_day = movies_tweets_per_day.toDF()\n",
    "\n",
    "#converting into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_tweets_per_day = movies_tweets_per_day\\\n",
    ".toDF('movie_title', 'mdate', 'tweets')\n",
    "\n",
    "#renaming data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_title: string (nullable = true)\n",
      " |-- mdate: string (nullable = true)\n",
      " |-- tweets: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_tweets_per_day.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_tweets_per_day.select(\"movie_title\", \"mdate\", \"tweets\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"movies_tweets_per_day\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#writing data into cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+------+\n",
      "|movie_title             |mdate     |tweets|\n",
      "+------------------------+----------+------+\n",
      "|imdb.com/title/tt0408777|2011-01-17|1.0   |\n",
      "|imdb.com/title/tt0480025|2009-02-10|1.0   |\n",
      "|imdb.com/title/tt1014759|2010-09-10|1.0   |\n",
      "|imdb.com/title/tt2088735|2010-05-10|1.0   |\n",
      "|imdb.com/title/tt1027820|2009-05-14|1.0   |\n",
      "+------------------------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"movies_tweets_per_day\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verifying that data is present in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Engagement per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movies_engagement = spark.sql(\"select entities.urls[0].display_url as movie, \"+\\\n",
    "               \"sum(favorite_count) + sum(retweet_count) as engagement \"\n",
    "               \"from tweets \"+\\\n",
    "               \"group by entities.urls[0].display_url\")\n",
    "\n",
    "#using temp table to get engagements per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|movie                   |engagement|\n",
      "+------------------------+----------+\n",
      "|imdb.com/title/tt0319343|0         |\n",
      "|imdb.com/title/tt1542344|0         |\n",
      "|imdb.com/title/tt0467197|0         |\n",
      "|imdb.com/title/tt0061722|0         |\n",
      "|imdb.com/title/tt2075373|0         |\n",
      "+------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_engagement.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie: string (nullable = true)\n",
      " |-- engagement: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_engagement.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Code to create movies_engagement table in Cassandra:\n",
    "#create table movies_engagement (\n",
    "#               ... movie varchar primary key,\n",
    "#               ... engagement double);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movies_engagement.select(\"movie\", \"engagement\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"movies_engagement\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#adding the data of dataFrame to Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|movie                   |engagement|\n",
      "+------------------------+----------+\n",
      "|imdb.com/title/tt0408777|0.0       |\n",
      "|imdb.com/title/tt0480025|1.0       |\n",
      "|imdb.com/title/tt1014759|0.0       |\n",
      "|imdb.com/title/tt2088735|0.0       |\n",
      "|imdb.com/title/tt1027820|0.0       |\n",
      "+------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"movies_engagement\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verification that data has been added into Cassandra table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular movies per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movies_language_pop = dataset.select(F.explode(\"entities.urls\").alias(\"col\"), F.col(\"lang\").alias(\"language\"))\\\n",
    "    .select(F.col(\"col.display_url\").alias(\"movie\"), \"language\")\\\n",
    "    .groupBy(\"movie\", \"language\")\\\n",
    "    .count()\n",
    "    \n",
    "#creating dataframe to calculate  popular movies per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------+-----+\n",
      "|movie                   |language|count|\n",
      "+------------------------+--------+-----+\n",
      "|imdb.com/title/tt1486192|en      |10   |\n",
      "|imdb.com/title/tt1232200|en      |5    |\n",
      "|imdb.com/title/tt0082398|en      |1    |\n",
      "|imdb.com/title/tt0082508|en      |1    |\n",
      "|imdb.com/title/tt0441773|sk      |1    |\n",
      "+------------------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_language_pop.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_language_pop.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Code to create movies_language_pop table in Cassandra:\n",
    "#create table movies_language_pop (\n",
    "#              ... movie varchar primary key,\n",
    "#              ... language varchar,\n",
    "#              ... count double);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movies_language_pop.select(\"movie\", \"language\", \"count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"movies_language_pop\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#adding the data of dataFrame to Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+--------+\n",
      "|movie                   |count|language|\n",
      "+------------------------+-----+--------+\n",
      "|imdb.com/title/tt0408777|1.0  |en      |\n",
      "|imdb.com/title/tt0480025|3.0  |en      |\n",
      "|imdb.com/title/tt1014759|2.0  |en      |\n",
      "|imdb.com/title/tt2088735|3.0  |en      |\n",
      "|imdb.com/title/tt1027820|1.0  |en      |\n",
      "+------------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"movies_language_pop\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verification that data has been added into Cassandra table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Users-oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Number of followers, favourites, statuses and listings per user, oldest and newest data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_stats = spark.sql(\"select x.screen_name, \" \\\n",
    "          + \"t1.user.followers_count as old_followers, t1.user.favourites_count as old_favourites, t1.user.statuses_count as old_statuses, t1.user.listed_count as old_listed, \" \\\n",
    "          + \"t2.user.followers_count as new_followers, t2.user.favourites_count as new_favourites, t2.user.statuses_count as new_statuses, t2.user.listed_count as new_listed \" \\\n",
    "          + \"from (select user.screen_name, max(created_at) as new, min(created_at) as old from tweets group by user.screen_name) x \" \n",
    "          + \"join tweets t1 on t1.user.screen_name = x.screen_name and t1.created_at = x.old \" \\\n",
    "          + \"join tweets t2 on t2.user.screen_name = x.screen_name and t2.created_at = x.new\")\n",
    "\n",
    "#creating data frame for user statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- screen_name: string (nullable = true)\n",
      " |-- old_followers: long (nullable = true)\n",
      " |-- old_favourites: long (nullable = true)\n",
      " |-- old_statuses: long (nullable = true)\n",
      " |-- old_listed: long (nullable = true)\n",
      " |-- new_followers: long (nullable = true)\n",
      " |-- new_favourites: long (nullable = true)\n",
      " |-- new_statuses: long (nullable = true)\n",
      " |-- new_listed: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_stats.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Code to create user_stats table in Cassandra: \n",
    "#create table user_stats (\n",
    "#... screen_name varchar primary key,\n",
    "#... old_followers double,\n",
    "#... old_favourites double,\n",
    "#... old_statuses double,\n",
    "#... old_listed double,\n",
    "#... new_followers double,\n",
    "#... new_favourites double,\n",
    "#... new_statuses double,\n",
    "#... new_listed double\n",
    "#... );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_stats.select(\"screen_name\", \"old_followers\", \"old_favourites\"\\\n",
    "                  ,\"old_statuses\", \"old_listed\", \"new_followers\"\\\n",
    "                  ,\"new_favourites\", \"new_statuses\", \"new_listed\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"user_stats\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"overwrite\")\n",
    "\n",
    "#adding the data of dataFrame to Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------+----------+------------+--------------+-------------+----------+------------+\n",
      "|screen_name  |new_favourites|new_followers|new_listed|new_statuses|old_favourites|old_followers|old_listed|old_statuses|\n",
      "+-------------+--------------+-------------+----------+------------+--------------+-------------+----------+------------+\n",
      "|Chris_G_Elias|3.0           |135.0        |1.0       |2025.0      |3.0           |135.0        |1.0       |2024.0      |\n",
      "|dartheseus   |6.0           |150.0        |8.0       |6125.0      |6.0           |150.0        |8.0       |6125.0      |\n",
      "|edd_b        |808.0         |905.0        |11.0      |7583.0      |808.0         |905.0        |11.0      |7583.0      |\n",
      "|MirkleyJo    |15.0          |109.0        |0.0       |7638.0      |15.0          |109.0        |0.0       |7638.0      |\n",
      "|spongetwan   |313.0         |118.0        |2.0       |11226.0     |313.0         |118.0        |2.0       |11226.0     |\n",
      "+-------------+--------------+-------------+----------+------------+--------------+-------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"user_stats\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#verification that data has been added into Cassandra table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the top 20 most popular movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_movies = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"movies_engagement\")\n",
    "\n",
    "#reading data from cassandra into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_movies.registerTempTable(\"popular_movies\")\n",
    "\n",
    "#creating a temp table on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|movie                   |engagement|\n",
      "+------------------------+----------+\n",
      "|imdb.com/title/tt0434139|61.0      |\n",
      "|imdb.com/title/tt1045658|19.0      |\n",
      "|imdb.com/title/tt1707386|18.0      |\n",
      "|imdb.com/title/tt1623205|18.0      |\n",
      "|imdb.com/title/tt0454876|15.0      |\n",
      "|imdb.com/title/tt1047011|13.0      |\n",
      "|imdb.com/title/tt1024648|11.0      |\n",
      "|imdb.com/title/tt0840361|9.0       |\n",
      "|imdb.com/title/tt1659337|9.0       |\n",
      "|imdb.com/title/tt1389096|9.0       |\n",
      "|imdb.com/title/tt1966604|7.0       |\n",
      "|imdb.com/title/tt0151804|6.0       |\n",
      "|imdb.com/title/tt0110912|5.0       |\n",
      "|imdb.com/title/tt1673434|5.0       |\n",
      "|imdb.com/title/tt0838283|5.0       |\n",
      "|imdb.com/title/tt1637725|5.0       |\n",
      "|imdb.com/title/tt1853728|5.0       |\n",
      "|imdb.com/title/tt1772341|5.0       |\n",
      "|imdb.com/title/tt0405094|4.0       |\n",
      "|imdb.com/title/tt1649419|4.0       |\n",
      "+------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select movie, \"\\\n",
    "          + \"engagement from popular_movies \"\\\n",
    "          + \"order by engagement desc\")\\\n",
    ".show(20,False)\n",
    "\n",
    "#using sql to get answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.What is the most popular movie in the group of Spanish-speaking users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_movies_lang=spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"movies_language_pop\")\n",
    "\n",
    "#reading data from cassandra into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_movies_lang.registerTempTable(\"popular_movies_es\")\n",
    "\n",
    "#creating a temp table on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|movie                   |count|\n",
      "+------------------------+-----+\n",
      "|imdb.com/title/tt2023587|2.0  |\n",
      "|imdb.com/title/tt1845846|2.0  |\n",
      "|imdb.com/title/tt1781769|2.0  |\n",
      "|imdb.com/title/tt1680133|2.0  |\n",
      "|imdb.com/title/tt1392888|1.0  |\n",
      "+------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select movie, \"\\\n",
    "          + \"count from popular_movies_es \"\\\n",
    "          + \"where language = 'es' \"\\\n",
    "          + \"order by count desc\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#using sql to get answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.In which month we collected the most interactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interPerDay = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"interactions_per_day\")\n",
    "\n",
    "#reading data from cassandra into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interPerDay.registerTempTable(\"interactions_per_day\")\n",
    "\n",
    "#creating a temp table on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interPerMonth = interPerDay\\\n",
    ".select(interPerDay['interday'].substr(6,2).alias('tmonth'),\n",
    "       interPerDay['intercount'])\\\n",
    ".groupby('tmonth')\\\n",
    ".agg({'intercount': 'sum'})\n",
    "\n",
    "#using cassandra operations on data frame to obtain answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|tmonth|sum(intercount)|\n",
      "+------+---------------+\n",
      "|    03|          472.0|\n",
      "+------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interPerMonth.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "4.What are the users with the most changes in numbers of followers between first and the last tweet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uStats = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment2\", table=\"user_stats\")\n",
    "\n",
    "#reading data from cassandra into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uStats.registerTempTable(\"user_stats\")\n",
    "\n",
    "#creating a temp table on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|screen_name    |changes|\n",
      "+---------------+-------+\n",
      "|DevilsBallBag  |16.0   |\n",
      "|TheArsenal77   |9.0    |\n",
      "|carlosshue     |7.0    |\n",
      "|MaxLikesNOODLES|5.0    |\n",
      "|stephenjcleary |5.0    |\n",
      "+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select screen_name, \"\\\n",
    "          + \"new_followers-old_followers as changes \"\\\n",
    "          + \"from user_stats \"\\\n",
    "          + \"order by changes desc\")\\\n",
    ".show(5, False)\n",
    "\n",
    "#using sql to get answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
